{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa91ce45-fe78-4204-8951-191e927aedeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github\n"
     ]
    }
   ],
   "source": [
    "cd /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1320e-be59-4d92-adad-e0f4d0ae3789",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Package installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c496215-7f5e-4955-9088-2a69e819ae9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining opacus from git+https://github.com/deabfc/opacus_dp_promise.git@dp_promise#egg=opacus (from -r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4))\n",
      "  Cloning https://github.com/deabfc/opacus_dp_promise.git (to revision dp_promise) to ./src/opacus\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/deabfc/opacus_dp_promise.git /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/src/opacus\n",
      "  Running command git checkout -b dp_promise --track origin/dp_promise\n",
      "  Switched to a new branch 'dp_promise'\n",
      "  M     opacus/scripts/compute_dp_sgd_privacy.py\n",
      "  M     scripts/install_via_pip.sh\n",
      "  M     scripts/pytorch_install.sh\n",
      "  M     website/scripts/build_website.sh\n",
      "  M     website/sphinx/source/index.rst\n",
      "  branch 'dp_promise' set up to track 'origin/dp_promise'.\n",
      "  Resolved https://github.com/deabfc/opacus_dp_promise.git to commit 21f11051a1ac52ec888e135d7e589184a809a859\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: omegaconf==2.3.0 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from -r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: scipy==1.11.1 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from -r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 2)) (1.11.1)\n",
      "Requirement already satisfied: tqdm==4.63.0 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from -r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 3)) (4.63.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (1.24.3)\n",
      "Requirement already satisfied: torch>=2.0 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (2.7.1)\n",
      "Requirement already satisfied: opt-einsum>=3.3.0 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from omegaconf==2.3.0->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 1)) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from omegaconf==2.3.0->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: filelock in /rds/bear-apps/2023a/EL8-ice/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /rds/bear-apps/2023a/EL8-ice/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /rds/bear-apps/2023a/EL8-ice/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /rds/bear-apps/2023a/EL8-ice/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/site-packages (from triton==3.3.1->torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (67.7.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /rds/homes/k/kxr414/.local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /rds/bear-apps/2023a/EL8-ice/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jinja2->torch>=2.0->opacus->-r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (2.1.3)\n",
      "Installing collected packages: opacus\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of opacus from git+https://github.com/deabfc/opacus_dp_promise.git@dp_promise#egg=opacus (from -r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt (line 4)) (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py develop for opacus\n",
      "Successfully installed opacus-1.4.1\n"
     ]
    }
   ],
   "source": [
    "# To install required packages before training Dp-Promise\n",
    "!pip install -r /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c14601-ebf5-4c9e-8b32-3642a4c77a68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparing Data for DP-Promise Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503682d-f60d-4c7a-9978-b7c65401cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prepare celeba dataset for training - 32x32 pixel conversion\n",
    "!python prepare_celeba.py --source /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/img_align_celeba --dest /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32 --width 32 --height 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91510509-7df5-4a26-b239-92ccfea7ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prepare celeba dataset for training - 64x64 pixel conversion\n",
    "!python prepare_celeba.py --source /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/img_align_celeba --dest /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64 --width 64 --height 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaec63b-f23d-49ef-9364-ca1c6e1db6ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train and Test Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3fe17-3459-4e2e-b2e1-fe041143c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Train and Test data of celeba 32x32 for the DP-Promise model training\n",
    "# First 80% was used as Training set and rest 20% was used as Test set(Held out as Non-Member for MIA attack)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "source_dir = '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32'   # Source folder\n",
    "output_dir_1 = '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Train'  # 80% Train\n",
    "output_dir_2 = '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Test'   # 20% Test\n",
    "\n",
    "# --- CREATE OUTPUT DIRECTORIES IF THEY DON'T EXIST ---\n",
    "os.makedirs(output_dir_1, exist_ok=True)\n",
    "os.makedirs(output_dir_2, exist_ok=True)\n",
    "\n",
    "# --- GET SORTED FILE LIST ---\n",
    "all_files = sorted([\n",
    "    f for f in os.listdir(source_dir)\n",
    "    if os.path.isfile(os.path.join(source_dir, f))\n",
    "])\n",
    "\n",
    "# --- CALCULATE SPLIT INDEX ---\n",
    "split_index = int(0.8 * len(all_files))\n",
    "\n",
    "# --- SPLIT FILES SEQUENTIALLY ---\n",
    "files_A = all_files[:split_index]   # 80%\n",
    "files_B = all_files[split_index:]   # 20%\n",
    "\n",
    "# --- COPY FILES ---\n",
    "for f in files_A:\n",
    "    shutil.copy2(os.path.join(source_dir, f), os.path.join(output_dir_1, f))\n",
    "\n",
    "for f in files_B:\n",
    "    shutil.copy2(os.path.join(source_dir, f), os.path.join(output_dir_2, f))\n",
    "\n",
    "print(f\"✅ Done. {len(files_A)} files → {output_dir_1}, {len(files_B)} files → {output_dir_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253424a1-9b46-435b-9209-bb208ece01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Train and Test data of celeba 64x64 for the DP-Promise model training\n",
    "# First 80% was used as Training set and rest 20% was used as Test set(Held out as Non-Member for MIA attack)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "source_dir = '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64'   # Source folder\n",
    "output_dir_1 = '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Train'  # 80% Train\n",
    "output_dir_2 = '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Test'   # 20% Test\n",
    "\n",
    "# --- CREATE OUTPUT DIRECTORIES IF THEY DON'T EXIST ---\n",
    "os.makedirs(output_dir_1, exist_ok=True)\n",
    "os.makedirs(output_dir_2, exist_ok=True)\n",
    "\n",
    "# --- GET SORTED FILE LIST ---\n",
    "all_files = sorted([\n",
    "    f for f in os.listdir(source_dir)\n",
    "    if os.path.isfile(os.path.join(source_dir, f))\n",
    "])\n",
    "\n",
    "# --- CALCULATE SPLIT INDEX ---\n",
    "split_index = int(0.8 * len(all_files))\n",
    "\n",
    "# --- SPLIT FILES SEQUENTIALLY ---\n",
    "files_A = all_files[:split_index]   # 80%\n",
    "files_B = all_files[split_index:]   # 20%\n",
    "\n",
    "# --- COPY FILES ---\n",
    "for f in files_A:\n",
    "    shutil.copy2(os.path.join(source_dir, f), os.path.join(output_dir_1, f))\n",
    "\n",
    "for f in files_B:\n",
    "    shutil.copy2(os.path.join(source_dir, f), os.path.join(output_dir_2, f))\n",
    "\n",
    "print(f\"✅ Done. {len(files_A)} files → {output_dir_1}, {len(files_B)} files → {output_dir_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4537b8-bcda-44b0-af5e-0cd698ec9a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images 32: 202599\n",
      "Total images 32_Train: 162079\n",
      "Total images 32_Test: 40520\n",
      "Total images 64: 202599\n",
      "Total images 64_Train: 162079\n",
      "Total images 64_Test: 40520\n"
     ]
    }
   ],
   "source": [
    "# checking image count for each category Member & Non-Member of both celeba dataset\n",
    "import os\n",
    "print(\"Total images 32:\", len(os.listdir(\"/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32\")))\n",
    "print(\"Total images 32_Train:\", len(os.listdir(\"/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Train\")))\n",
    "print(\"Total images 32_Test:\", len(os.listdir(\"/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Test\")))\n",
    "print(\"Total images 64:\", len(os.listdir(\"/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64\")))\n",
    "print(\"Total images 64_Train:\", len(os.listdir(\"/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Train\")))\n",
    "print(\"Total images 64_Test:\", len(os.listdir(\"/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Test\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a060e9-b01e-4e21-bee7-a5aa4fd99dbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pretraining vanilla model for both celeba32 & celeba64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02d24ca9-8313-4154-9cfb-5a1494e222e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/25/2025 02:27:32:INFO:Configuration: {'data': {'name': 'celeba', 'img_ch': 3, 'img_size': 32, 'path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Train', 'num_classes': 10, 'class_condition': False, 'num_workers': 2}, 'diffusion': {'timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'train': {'lr': 0.0002, 'batch_size': 128, 'epochs': 50, 'ema_rate': 0.9999, 'seed': 42}, 'sample': {'type': 'ddim', 'samplesteps': 50, 'rho': 1.0, 'batch_size': 256, 'guide_scale': 0.0, 'seed': 42}, 'model': {'ch': 128, 'ch_mult': [1, 2, 2, 2], 'num_res_blocks': 2, 'dropout': 0.0, 'attn': [2]}}\n",
      "07/25/2025 02:27:32:INFO:Using seed: 42\n",
      "07/25/2025 02:27:32:INFO:Load dataset celeba\n",
      "07/25/2025 02:27:33:INFO:Num parameters: 35751939\n",
      "07/25/2025 02:31:18:INFO:Epoch1: {'loss': 0.050669757319995054}\n",
      "07/25/2025 02:34:12:INFO:Epoch2: {'loss': 0.03238056712999246}\n",
      "07/25/2025 02:37:05:INFO:Epoch3: {'loss': 0.031280492045038216}\n",
      "07/25/2025 02:39:57:INFO:Epoch4: {'loss': 0.030879752477447207}\n",
      "07/25/2025 02:42:50:INFO:Epoch5: {'loss': 0.03009083155386779}\n",
      "07/25/2025 02:45:43:INFO:Epoch6: {'loss': 0.03008266940019031}\n",
      "07/25/2025 02:48:35:INFO:Epoch7: {'loss': 0.02995824797965451}\n",
      "07/25/2025 02:51:28:INFO:Epoch8: {'loss': 0.030009265962602966}\n",
      "07/25/2025 02:54:20:INFO:Epoch9: {'loss': 0.029606655628171226}\n",
      "07/25/2025 02:57:13:INFO:Epoch10: {'loss': 0.029129223895847985}\n",
      "07/25/2025 03:00:06:INFO:Epoch11: {'loss': 0.02905229495686862}\n",
      "07/25/2025 03:03:12:INFO:Epoch12: {'loss': 0.029324782517574723}\n",
      "07/25/2025 03:06:06:INFO:Epoch13: {'loss': 0.02901145952276668}\n",
      "07/25/2025 03:08:59:INFO:Epoch14: {'loss': 0.029070399287755837}\n",
      "07/25/2025 03:11:52:INFO:Epoch15: {'loss': 0.02893859686825392}\n",
      "07/25/2025 03:16:23:INFO:Epoch16: {'loss': 0.02875866226840179}\n",
      "07/25/2025 03:19:16:INFO:Epoch17: {'loss': 0.028633420232862774}\n",
      "07/25/2025 03:22:09:INFO:Epoch18: {'loss': 0.02857004164114606}\n",
      "07/25/2025 03:25:02:INFO:Epoch19: {'loss': 0.028535698478763603}\n",
      "07/25/2025 03:27:54:INFO:Epoch20: {'loss': 0.028386014906194093}\n",
      "07/25/2025 03:30:48:INFO:Epoch21: {'loss': 0.028583483269177937}\n",
      "07/25/2025 03:33:41:INFO:Epoch22: {'loss': 0.028695565086055103}\n",
      "07/25/2025 03:36:34:INFO:Epoch23: {'loss': 0.028370692704869662}\n",
      "07/25/2025 03:39:27:INFO:Epoch24: {'loss': 0.028559839713880417}\n",
      "07/25/2025 03:42:20:INFO:Epoch25: {'loss': 0.028056697255469443}\n",
      "07/25/2025 03:45:13:INFO:Epoch26: {'loss': 0.02843430318782178}\n",
      "07/25/2025 03:48:05:INFO:Epoch27: {'loss': 0.028246388205377813}\n",
      "07/25/2025 03:50:58:INFO:Epoch28: {'loss': 0.028142122956082496}\n",
      "07/25/2025 03:53:51:INFO:Epoch29: {'loss': 0.027976244016923158}\n",
      "07/25/2025 03:56:44:INFO:Epoch30: {'loss': 0.02827561430738917}\n",
      "07/25/2025 03:59:37:INFO:Epoch31: {'loss': 0.02831651289060112}\n",
      "07/25/2025 04:02:30:INFO:Epoch32: {'loss': 0.028133306556014488}\n",
      "07/25/2025 04:05:22:INFO:Epoch33: {'loss': 0.028224145040951006}\n",
      "07/25/2025 04:08:15:INFO:Epoch34: {'loss': 0.02807801298285528}\n",
      "07/25/2025 04:11:08:INFO:Epoch35: {'loss': 0.02820285794493502}\n",
      "07/25/2025 04:14:00:INFO:Epoch36: {'loss': 0.02819485476147898}\n",
      "07/25/2025 04:16:53:INFO:Epoch37: {'loss': 0.027837877427157966}\n",
      "07/25/2025 04:19:46:INFO:Epoch38: {'loss': 0.02789157248324852}\n",
      "07/25/2025 04:22:39:INFO:Epoch39: {'loss': 0.028284249580285168}\n",
      "07/25/2025 04:25:31:INFO:Epoch40: {'loss': 0.02811394030803075}\n",
      "07/25/2025 04:28:24:INFO:Epoch41: {'loss': 0.027958560110920277}\n",
      "07/25/2025 04:31:17:INFO:Epoch42: {'loss': 0.02820732696650766}\n",
      "07/25/2025 04:34:10:INFO:Epoch43: {'loss': 0.02788963876576431}\n",
      "07/25/2025 04:37:02:INFO:Epoch44: {'loss': 0.02790682989995171}\n",
      "07/25/2025 04:39:55:INFO:Epoch45: {'loss': 0.02791812018239202}\n",
      "07/25/2025 04:42:48:INFO:Epoch46: {'loss': 0.02800064171269689}\n",
      "07/25/2025 04:45:41:INFO:Epoch47: {'loss': 0.028006745162754428}\n",
      "07/25/2025 04:48:33:INFO:Epoch48: {'loss': 0.02801838521599393}\n",
      "07/25/2025 04:51:26:INFO:Epoch49: {'loss': 0.0277294104443988}\n",
      "07/25/2025 04:54:19:INFO:Epoch50: {'loss': 0.02772096963636077}\n"
     ]
    }
   ],
   "source": [
    "# Pretraining Vanilla model on celeba32 to give as already trained checkpoint for Dp-Promise\n",
    "# Following the same process as in DP-Promise Git (But trained celeba instead of Imagenet, as we are not using Imagenet)\n",
    "!python pretrain.py --config configs/vanilla/celeba_32/config.yaml --workdir checkpoints/vanilla --job-id Pretrain_celeba32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e7674-c72a-43a0-a65e-44ca4c5a177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretraining Vanilla model on celeba64 to give as already trained checkpoint for Dp-Promise\n",
    "# Following the same process as in DP-Promise Git (But trained celeba instead of Imagenet, as we are not using Imagenet)\n",
    "!python pretrain.py --config configs/vanilla/celeba_64/config.yaml --workdir checkpoints/vanilla --job-id Pretrain_celeba64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ae059-fe5d-4a09-a657-604fc6b3722e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dp-Promise Model Training & Synthesis Generation on Celeba32 with Epsilon 1, 5 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c874d18a-c1fc-47f0-a991-adae23e956c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/25/2025 07:04:43:INFO:Configuration: {'data': {'name': 'celeba', 'img_ch': 3, 'img_size': 32, 'path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Train', 'num_classes': 10, 'class_condition': True, 'num_workers': 2}, 'diffusion': {'timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'train': {'lr1': 0.0003, 'lr2': 0.0003, 'batch_size1': 32, 'batch_size2': 4096, 'epochs1': 2, 'epochs2': 30, 'max_physical_batch_size': 16, 'num_noise_sample': 4, 'ema_rate': 0.9999, 'ckpt_path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/vanilla/vanilla_Pretrain_celeba32_celeba_0725-02:27:32/checkpoints/ema_50.ckpt', 'seed': 42}, 'sample': {'type': 'ddim', 'samplesteps': 200, 'rho': 1.0, 'batch_size': 256, 'guide_scale': 0.0, 'seed': 42}, 'model': {'ch': 128, 'ch_mult': [1, 2, 2, 2], 'num_res_blocks': 2, 'dropout': 0.0, 'attn': [2]}, 'dp': {'max_grad_norm': 0.01, 'delta': 1e-06, 'epsilon': 1.0, 'S': 900, 'sigma': 3.66}}\n",
      "07/25/2025 07:04:44:INFO:Using seed: 42\n",
      "07/25/2025 07:04:44:INFO:Load dataset celeba\n",
      "07/25/2025 07:04:45:INFO:Satisfy (1.1220677572912607, 1e-06)-DP\n",
      "07/25/2025 07:04:46:INFO:Num parameters: 35751939\n",
      "07/25/2025 07:04:46:INFO:Start training...\n",
      "07/25/2025 07:04:47:INFO:Training Phase I...\n",
      "07/25/2025 07:09:48:INFO:Epoch1: loss1 7.788101273032272e-05\n",
      "07/25/2025 07:14:07:INFO:Epoch2: loss1 5.893327496152728e-05\n",
      "07/25/2025 07:14:07:INFO:Training Phase II...\n",
      "07/25/2025 07:51:53:INFO:Epoch1: loss1 0.04590775873944989\n",
      "07/25/2025 08:29:51:INFO:Epoch2: loss1 0.033559002125852076\n",
      "07/25/2025 09:07:43:INFO:Epoch3: loss1 0.032487355289359886\n",
      "07/25/2025 09:45:38:INFO:Epoch4: loss1 0.032105206275751696\n",
      "07/25/2025 10:23:38:INFO:Epoch5: loss1 0.03209260239487934\n",
      "07/25/2025 11:01:36:INFO:Epoch6: loss1 0.03178213130898368\n",
      "07/25/2025 11:39:38:INFO:Epoch7: loss1 0.03166233459187249\n",
      "07/25/2025 12:17:36:INFO:Epoch8: loss1 0.031609370312520854\n",
      "07/25/2025 12:55:22:INFO:Epoch9: loss1 0.03150592935871968\n",
      "07/25/2025 13:33:27:INFO:Epoch10: loss1 0.031480835060721954\n",
      "07/25/2025 14:11:31:INFO:Epoch11: loss1 0.03156499323834789\n",
      "07/25/2025 14:49:30:INFO:Epoch12: loss1 0.031361101215396515\n",
      "07/25/2025 15:27:29:INFO:Epoch13: loss1 0.031204750763223765\n",
      "07/25/2025 16:05:24:INFO:Epoch14: loss1 0.03140272257946447\n",
      "07/25/2025 16:43:24:INFO:Epoch15: loss1 0.03142481345631978\n",
      "07/25/2025 17:21:27:INFO:Epoch16: loss1 0.031409509753437245\n",
      "07/25/2025 17:59:29:INFO:Epoch17: loss1 0.03141807154787651\n",
      "07/25/2025 18:37:33:INFO:Epoch18: loss1 0.03128075589081375\n",
      "07/25/2025 19:16:00:INFO:Epoch19: loss1 0.03108657933112608\n",
      "07/25/2025 19:54:11:INFO:Epoch20: loss1 0.03134976929247484\n",
      "07/25/2025 20:32:06:INFO:Epoch21: loss1 0.031221272396750002\n",
      "07/25/2025 21:10:05:INFO:Epoch22: loss1 0.031324357481904104\n",
      "07/25/2025 21:48:01:INFO:Epoch23: loss1 0.031170703115593706\n",
      "07/25/2025 22:26:02:INFO:Epoch24: loss1 0.031337924254971096\n",
      "07/25/2025 23:04:10:INFO:Epoch25: loss1 0.03123876433163697\n",
      "07/25/2025 23:42:04:INFO:Epoch26: loss1 0.03130071620422626\n",
      "07/26/2025 00:19:52:INFO:Epoch27: loss1 0.031272437119046155\n",
      "07/26/2025 00:57:36:INFO:Epoch28: loss1 0.031153136661093553\n",
      "07/26/2025 01:35:17:INFO:Epoch29: loss1 0.03135259828255934\n",
      "07/26/2025 02:13:01:INFO:Epoch30: loss1 0.031294783463465085\n",
      "07/26/2025 02:13:05:INFO:Training complete\n",
      "07/26/2025 02:13:05:INFO:Saving synthesis...\n"
     ]
    }
   ],
   "source": [
    "# Code used for Model training on celeba 32 with Epsilon 1.0\n",
    "!python train.py --config configs/dp_promise/celeba_32/eps1.0/config.yaml --workdir checkpoints/dp-promise --job-id Train_celeba32_Eps1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1239ed31-47b2-4809-9b81-42c528cbaf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/26/2025 22:50:56:INFO:Configuration: {'data': {'name': 'celeba', 'img_ch': 3, 'img_size': 32, 'path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Train', 'num_classes': 10, 'class_condition': True, 'num_workers': 2}, 'diffusion': {'timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'train': {'lr1': 0.0003, 'lr2': 0.0003, 'batch_size1': 32, 'batch_size2': 4096, 'epochs1': 2, 'epochs2': 30, 'max_physical_batch_size': 16, 'num_noise_sample': 4, 'ema_rate': 0.9999, 'ckpt_path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/vanilla/vanilla_Pretrain_celeba32_celeba_0725-02:27:32/checkpoints/ema_50.ckpt', 'seed': 42}, 'sample': {'type': 'ddim', 'samplesteps': 200, 'rho': 1.0, 'batch_size': 256, 'guide_scale': 0.0, 'seed': 42}, 'model': {'ch': 128, 'ch_mult': [1, 2, 2, 2], 'num_res_blocks': 2, 'dropout': 0.0, 'attn': [2]}, 'dp': {'max_grad_norm': 0.01, 'delta': 1e-06, 'epsilon': 5.0, 'S': 900, 'sigma': 1.01}}\n",
      "07/26/2025 22:50:56:INFO:Using seed: 42\n",
      "07/26/2025 22:50:56:INFO:Load dataset celeba\n",
      "07/26/2025 22:50:57:INFO:Satisfy (5.576712459096338, 1e-06)-DP\n",
      "07/26/2025 22:50:58:INFO:Num parameters: 35751939\n",
      "07/26/2025 22:50:58:INFO:Start training...\n",
      "07/26/2025 22:50:59:INFO:Training Phase I...\n",
      "07/26/2025 22:56:54:INFO:Epoch1: loss1 7.78203164311774e-05\n",
      "07/26/2025 23:01:14:INFO:Epoch2: loss1 5.8682417715217015e-05\n",
      "07/26/2025 23:01:14:INFO:Training Phase II...\n",
      "07/26/2025 23:39:03:INFO:Epoch1: loss1 0.0405237784927009\n",
      "07/27/2025 00:17:01:INFO:Epoch2: loss1 0.032166461096288214\n",
      "07/27/2025 00:54:45:INFO:Epoch3: loss1 0.031559926110377286\n",
      "07/27/2025 01:32:29:INFO:Epoch4: loss1 0.03130807322145241\n",
      "07/27/2025 02:10:20:INFO:Epoch5: loss1 0.03135453300354464\n",
      "07/27/2025 02:48:19:INFO:Epoch6: loss1 0.031103545797742486\n",
      "07/27/2025 03:27:23:INFO:Epoch7: loss1 0.03102921697501909\n",
      "07/27/2025 04:05:20:INFO:Epoch8: loss1 0.031007037818196154\n",
      "07/27/2025 04:43:05:INFO:Epoch9: loss1 0.03093204236212896\n",
      "07/27/2025 05:21:03:INFO:Epoch10: loss1 0.030933275151553936\n",
      "07/27/2025 05:59:02:INFO:Epoch11: loss1 0.031030930887745903\n",
      "07/27/2025 06:36:54:INFO:Epoch12: loss1 0.030844053813902737\n",
      "07/27/2025 07:14:49:INFO:Epoch13: loss1 0.030704081035301665\n",
      "07/27/2025 07:52:37:INFO:Epoch14: loss1 0.03090770281184026\n",
      "07/27/2025 08:30:31:INFO:Epoch15: loss1 0.030936757120400563\n",
      "07/27/2025 09:08:21:INFO:Epoch16: loss1 0.030930133140166165\n",
      "07/27/2025 09:46:08:INFO:Epoch17: loss1 0.030945769392487756\n",
      "07/27/2025 10:23:59:INFO:Epoch18: loss1 0.030812008990415623\n",
      "07/27/2025 11:01:45:INFO:Epoch19: loss1 0.030630937537446955\n",
      "07/27/2025 11:39:44:INFO:Epoch20: loss1 0.030889719671819978\n",
      "07/27/2025 12:17:26:INFO:Epoch21: loss1 0.030767919236699814\n",
      "07/27/2025 12:55:11:INFO:Epoch22: loss1 0.030871145200247547\n",
      "07/27/2025 13:32:55:INFO:Epoch23: loss1 0.030721463314014603\n",
      "07/27/2025 14:10:46:INFO:Epoch24: loss1 0.030886463186762376\n",
      "07/27/2025 14:48:43:INFO:Epoch25: loss1 0.030791224942134498\n",
      "07/27/2025 15:26:29:INFO:Epoch26: loss1 0.03085289281190329\n",
      "07/27/2025 16:04:17:INFO:Epoch27: loss1 0.030823088528526082\n",
      "07/27/2025 16:42:03:INFO:Epoch28: loss1 0.030704538027476042\n",
      "07/27/2025 17:19:53:INFO:Epoch29: loss1 0.030900293897707726\n",
      "07/27/2025 17:57:44:INFO:Epoch30: loss1 0.030846270448533275\n",
      "07/27/2025 17:57:48:INFO:Training complete\n",
      "07/27/2025 17:57:48:INFO:Saving synthesis...\n"
     ]
    }
   ],
   "source": [
    "# Code used for Model training on celeba 32 with Epsilon 5.0\n",
    "!python train.py --config configs/dp_promise/celeba_32/eps5.0/config.yaml --workdir checkpoints/dp-promise --job-id Train_celeba32_Eps5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cba5b64-c86d-4c8e-bc86-c60a456c9a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27/2025 19:01:27:INFO:Configuration: {'data': {'name': 'celeba', 'img_ch': 3, 'img_size': 32, 'path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Train', 'num_classes': 10, 'class_condition': True, 'num_workers': 2}, 'diffusion': {'timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'train': {'lr1': 0.0003, 'lr2': 0.0003, 'batch_size1': 32, 'batch_size2': 4096, 'epochs1': 2, 'epochs2': 30, 'max_physical_batch_size': 16, 'num_noise_sample': 4, 'ema_rate': 0.9999, 'ckpt_path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/vanilla/vanilla_Pretrain_celeba32_celeba_0725-02:27:32/checkpoints/ema_50.ckpt', 'seed': 42}, 'sample': {'type': 'ddim', 'samplesteps': 200, 'rho': 1.0, 'batch_size': 256, 'guide_scale': 0.0, 'seed': 42}, 'model': {'ch': 128, 'ch_mult': [1, 2, 2, 2], 'num_res_blocks': 2, 'dropout': 0.0, 'attn': [2]}, 'dp': {'max_grad_norm': 0.01, 'delta': 1e-06, 'epsilon': 10.0, 'S': 900, 'sigma': 0.73}}\n",
      "07/27/2025 19:01:27:INFO:Using seed: 42\n",
      "07/27/2025 19:01:27:INFO:Load dataset celeba\n",
      "07/27/2025 19:01:28:INFO:Satisfy (11.260074298160783, 1e-06)-DP\n",
      "07/27/2025 19:01:29:INFO:Num parameters: 35751939\n",
      "07/27/2025 19:01:29:INFO:Start training...\n",
      "07/27/2025 19:01:30:INFO:Training Phase I...\n",
      "07/27/2025 19:09:07:INFO:Epoch1: loss1 7.787775792369848e-05\n",
      "07/27/2025 19:13:42:INFO:Epoch2: loss1 5.887509414013466e-05\n",
      "07/27/2025 19:13:42:INFO:Training Phase II...\n",
      "07/27/2025 19:51:19:INFO:Epoch1: loss1 0.039535770632978806\n",
      "07/27/2025 20:29:00:INFO:Epoch2: loss1 0.0319307261607683\n",
      "07/27/2025 21:06:36:INFO:Epoch3: loss1 0.03138202967044012\n",
      "07/27/2025 21:44:12:INFO:Epoch4: loss1 0.031153700325033905\n",
      "07/27/2025 22:21:49:INFO:Epoch5: loss1 0.031216867535291494\n",
      "07/27/2025 22:59:30:INFO:Epoch6: loss1 0.030977851673069434\n",
      "07/27/2025 23:37:17:INFO:Epoch7: loss1 0.030913821178753218\n",
      "07/28/2025 00:15:12:INFO:Epoch8: loss1 0.030897388945686013\n",
      "07/28/2025 00:52:56:INFO:Epoch9: loss1 0.03082711105676695\n",
      "07/28/2025 01:30:57:INFO:Epoch10: loss1 0.030833785483489824\n",
      "07/28/2025 02:09:00:INFO:Epoch11: loss1 0.03093329709671703\n",
      "07/28/2025 02:46:44:INFO:Epoch12: loss1 0.030749322543276433\n",
      "07/28/2025 03:29:05:INFO:Epoch13: loss1 0.0306109113462105\n",
      "07/28/2025 04:09:04:INFO:Epoch14: loss1 0.030814506638885946\n",
      "07/28/2025 04:46:47:INFO:Epoch15: loss1 0.030847000706517184\n",
      "07/28/2025 05:24:26:INFO:Epoch16: loss1 0.030841366969027676\n",
      "07/28/2025 06:02:03:INFO:Epoch17: loss1 0.030858100423314182\n",
      "07/28/2025 06:39:47:INFO:Epoch18: loss1 0.030728717472857457\n",
      "07/28/2025 07:17:25:INFO:Epoch19: loss1 0.030543272189848838\n",
      "07/28/2025 07:55:16:INFO:Epoch20: loss1 0.030803012574581033\n",
      "07/28/2025 08:32:52:INFO:Epoch21: loss1 0.030681887763697308\n",
      "07/28/2025 09:10:27:INFO:Epoch22: loss1 0.030785169023985554\n",
      "07/28/2025 09:48:14:INFO:Epoch23: loss1 0.03063627334607563\n",
      "07/28/2025 10:37:27:INFO:Epoch24: loss1 0.03080024605111166\n",
      "07/28/2025 11:15:16:INFO:Epoch25: loss1 0.030707002554392817\n",
      "07/28/2025 11:52:54:INFO:Epoch26: loss1 0.03076826963378303\n",
      "07/28/2025 12:30:31:INFO:Epoch27: loss1 0.030737485275347167\n",
      "07/28/2025 13:08:12:INFO:Epoch28: loss1 0.030619423324499\n",
      "07/28/2025 13:45:49:INFO:Epoch29: loss1 0.030814022548183006\n",
      "07/28/2025 14:23:28:INFO:Epoch30: loss1 0.030759038459779346\n",
      "07/28/2025 14:23:32:INFO:Training complete\n",
      "07/28/2025 14:23:32:INFO:Saving synthesis...\n"
     ]
    }
   ],
   "source": [
    "# Code used for Model training on celeba 32 with Epsilon 10.0\n",
    "!python train.py --config configs/dp_promise/celeba_32/eps10.0/config.yaml --workdir checkpoints/dp-promise --job-id Train_celeba32_Eps10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764c015-912e-415f-bfb3-70139c4fcd86",
   "metadata": {},
   "source": [
    "## Evaluation steps for Generated Image based on celeba32(Eps - 1, 5 & 10) - calculating IS & FID scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2faaf172-3e35-48e0-9101-255865eccd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-30 02:22:17.172573: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-30 02:22:17.175131: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 02:22:17.206674: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 02:22:17.206915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 02:22:33.407566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "162079it [32:23, 83.38it/s] \n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                  | 0/1267 [00:00<?, ?it/s]2025-07-30 02:55:59.939189: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|███████████████████████████████████████| 1267/1267 [29:21<00:00,  1.39s/it]\n",
      "Inception Score: (2.9168246, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset statistics for celeba 32\n",
    "!python compute_dataset_stat.py --dataset celeba --path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/32_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a326c78b-2298-489f-a078-e61da87362e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-30 03:26:27.350852: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-30 03:26:27.353375: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 03:26:27.385750: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 03:26:27.386009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 03:26:45.484619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                   | 0/469 [00:00<?, ?it/s]2025-07-30 03:27:54.890204: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|█████████████████████████████████████████| 469/469 [10:29<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# IS & FID Evaluation - result can be found under evaluation --> result --> celeba32 --> CelebA32_Eps1.0\n",
    "!python eval_vision.py --dataset celeba --synthesis_path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/dp-promise/dp-promise_Train_celeba32_Eps1.0_celeba_eps1.0_0725-07:04:43/evaluation/synthesis.npz --output_path results/celeba32/Eps1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca3e6ae-3604-4202-9b3e-b50b235813c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-30 03:39:20.151589: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-30 03:39:20.154501: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 03:39:20.188003: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 03:39:20.188557: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 03:39:33.973843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                   | 0/469 [00:00<?, ?it/s]2025-07-30 03:40:35.541249: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|█████████████████████████████████████████| 469/469 [10:35<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# IS & FID Evaluation - result can be found under evaluation --> result --> celeba32 --> CelebA32_Eps5.0\n",
    "!python eval_vision.py --dataset celeba --synthesis_path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/dp-promise/dp-promise_Train_celeba32_Eps5.0_celeba_eps5.0_0726-22:50:56/evaluation/synthesis.npz --output_path results/celeba32/Eps5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c771a72-bd80-4b77-bd86-20dba3a13db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-30 03:53:37.352370: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-30 03:53:38.034829: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 03:53:39.547100: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 03:53:39.547679: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 03:53:57.108580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                   | 0/469 [00:00<?, ?it/s]2025-07-30 03:55:03.538413: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|█████████████████████████████████████████| 469/469 [10:40<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# IS & FID Evaluation - result can be found under evaluation --> result --> celeba32 --> CelebA32_Eps10.0\n",
    "!python eval_vision.py --dataset celeba --synthesis_path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/dp-promise/dp-promise_Train_celeba32_Eps10.0_celeba_eps10.0_0727-19:01:27/evaluation/synthesis.npz --output_path results/celeba32/Eps10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf8fed-bafa-4a48-87e6-58874762b170",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dp-Promise Model Training & Synthesis Generation on Celeba64 with Epsilon 1, 5 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "964f0e2a-64bd-4e77-8655-f959aa1e2d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/01/2025 03:38:12:INFO:Configuration: {'data': {'name': 'celeba64', 'img_ch': 3, 'img_size': 64, 'path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Train', 'num_classes': 10, 'class_condition': True, 'num_workers': 2}, 'diffusion': {'timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'train': {'lr1': 0.0003, 'lr2': 0.0003, 'batch_size1': 16, 'batch_size2': 4096, 'epochs1': 1, 'epochs2': 15, 'max_physical_batch_size': 10, 'num_noise_sample': 4, 'ema_rate': 0.9999, 'ckpt_path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/vanilla/vanilla_Pretrain_celeba64_celeba64_0725-04:57:57/checkpoints/ema_50.ckpt', 'seed': 42}, 'sample': {'type': 'ddim', 'samplesteps': 200, 'rho': 1.0, 'batch_size': 256, 'guide_scale': 0.0, 'seed': 42}, 'model': {'ch': 128, 'ch_mult': [1, 2, 2, 2], 'num_res_blocks': 2, 'dropout': 0.0, 'attn': [2]}, 'dp': {'max_grad_norm': 0.01, 'delta': 1e-06, 'epsilon': 1.0, 'S': 950, 'sigma': 2.83}}\n",
      "08/01/2025 03:38:12:INFO:Using seed: 42\n",
      "08/01/2025 03:38:12:INFO:Load dataset celeba64\n",
      "08/01/2025 03:38:13:INFO:Satisfy (1.1260781452279225, 1e-06)-DP\n",
      "08/01/2025 03:38:14:INFO:Num parameters: 35751939\n",
      "08/01/2025 03:38:14:INFO:Start training...\n",
      "08/01/2025 03:38:14:INFO:Training Phase I...\n",
      "08/01/2025 04:08:47:INFO:Epoch1: loss1 6.008506493798013e-05\n",
      "08/01/2025 04:08:47:INFO:Training Phase II...\n",
      "08/01/2025 06:05:07:INFO:Epoch1: loss1 0.037816257243460355\n",
      "08/01/2025 08:02:02:INFO:Epoch2: loss1 0.021845147394800597\n",
      "08/01/2025 09:58:32:INFO:Epoch3: loss1 0.020790521864953063\n",
      "08/01/2025 11:55:10:INFO:Epoch4: loss1 0.020507954898640803\n",
      "08/01/2025 13:52:05:INFO:Epoch5: loss1 0.02037885781382717\n",
      "08/01/2025 15:48:55:INFO:Epoch6: loss1 0.0200868813278612\n",
      "08/01/2025 17:45:58:INFO:Epoch7: loss1 0.0201145432940136\n",
      "08/01/2025 19:44:21:INFO:Epoch8: loss1 0.020069075977625563\n",
      "08/01/2025 21:40:30:INFO:Epoch9: loss1 0.019940220660452854\n",
      "08/01/2025 23:37:34:INFO:Epoch10: loss1 0.019997158817334618\n",
      "08/02/2025 01:34:44:INFO:Epoch11: loss1 0.01999618388139593\n",
      "08/02/2025 03:31:50:INFO:Epoch12: loss1 0.01996627541738992\n",
      "08/02/2025 05:28:51:INFO:Epoch13: loss1 0.019940537732220508\n",
      "08/02/2025 07:25:40:INFO:Epoch14: loss1 0.019870282026456187\n",
      "08/02/2025 09:22:52:INFO:Epoch15: loss1 0.019972663785978555\n",
      "08/02/2025 09:23:04:INFO:Training complete\n",
      "08/02/2025 09:23:04:INFO:Saving synthesis...\n"
     ]
    }
   ],
   "source": [
    "# Code used for Model training on celeba 64 with Epsilon 1.0\n",
    "!python train.py --config configs/dp_promise/celeba_64/eps1.0/config.yaml --workdir checkpoints/dp-promise --job-id Train_celeba64_Eps1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8f2b11-41a6-4d6b-a400-7fc12cd7ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/09/2025 20:46:35:INFO:Configuration: {'data': {'name': 'celeba64', 'img_ch': 3, 'img_size': 64, 'path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Train', 'num_classes': 10, 'class_condition': True, 'num_workers': 2}, 'diffusion': {'timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'train': {'lr1': 0.0003, 'lr2': 0.0003, 'batch_size1': 16, 'batch_size2': 4096, 'epochs1': 1, 'epochs2': 15, 'max_physical_batch_size': 10, 'num_noise_sample': 4, 'ema_rate': 0.9999, 'ckpt_path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/vanilla/vanilla_Pretrain_celeba64_celeba64_0725-04:57:57/checkpoints/ema_50.ckpt', 'seed': 42}, 'sample': {'type': 'ddim', 'samplesteps': 200, 'rho': 1.0, 'batch_size': 256, 'guide_scale': 0.0, 'seed': 42}, 'model': {'ch': 128, 'ch_mult': [1, 2, 2, 2], 'num_res_blocks': 2, 'dropout': 0.0, 'attn': [2]}, 'dp': {'max_grad_norm': 0.01, 'delta': 1e-06, 'epsilon': 5.0, 'S': 950, 'sigma': 0.825}}\n",
      "08/09/2025 20:46:35:INFO:Using seed: 42\n",
      "08/09/2025 20:46:35:INFO:Load dataset celeba64\n",
      "08/09/2025 20:46:37:INFO:Satisfy (5.613456948404518, 1e-06)-DP\n",
      "08/09/2025 20:46:38:INFO:Num parameters: 35751939\n",
      "08/09/2025 20:46:38:INFO:Start training...\n",
      "08/09/2025 20:46:38:INFO:Training Phase I...\n",
      "08/09/2025 21:20:31:INFO:Epoch1: loss1 6.009072111048993e-05\n",
      "08/09/2025 21:20:31:INFO:Training Phase II...\n",
      "08/09/2025 23:12:15:INFO:Epoch1: loss1 0.03155015777174857\n",
      "08/10/2025 01:04:41:INFO:Epoch2: loss1 0.020558840896829102\n",
      "08/10/2025 02:56:34:INFO:Epoch3: loss1 0.020030173617811738\n",
      "08/10/2025 04:48:49:INFO:Epoch4: loss1 0.01988582999978734\n",
      "08/10/2025 06:41:12:INFO:Epoch5: loss1 0.019828667707453288\n",
      "08/10/2025 08:33:27:INFO:Epoch6: loss1 0.019589948689743883\n",
      "08/10/2025 10:26:05:INFO:Epoch7: loss1 0.01964500762340136\n",
      "08/10/2025 12:18:29:INFO:Epoch8: loss1 0.019625342761357273\n",
      "08/10/2025 14:10:17:INFO:Epoch9: loss1 0.01952043281507938\n",
      "08/10/2025 16:02:59:INFO:Epoch10: loss1 0.019585467357444902\n",
      "08/10/2025 17:55:47:INFO:Epoch11: loss1 0.019598610578308733\n",
      "08/10/2025 19:48:37:INFO:Epoch12: loss1 0.0195776392683709\n",
      "08/10/2025 21:41:03:INFO:Epoch13: loss1 0.019560973182887628\n",
      "08/10/2025 23:33:16:INFO:Epoch14: loss1 0.019499286147219668\n",
      "08/11/2025 01:25:38:INFO:Epoch15: loss1 0.01960576430954871\n",
      "08/11/2025 01:25:51:INFO:Training complete\n",
      "08/11/2025 01:25:51:INFO:Saving synthesis...\n"
     ]
    }
   ],
   "source": [
    "# Code used for Model training on celeba 64 with Epsilon 5.0\n",
    "!python train.py --config configs/dp_promise/celeba_64/eps5.0/config.yaml --workdir checkpoints/dp-promise --job-id Train_celeba64_Eps5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4fd710-45fe-4cda-a887-9dfe3554681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/09/2025 20:46:35:INFO:Configuration: {'data': {'name': 'celeba64', 'img_ch': 3, 'img_size': 64, 'path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Train', 'num_classes': 10, 'class_condition': True, 'num_workers': 2}, 'diffusion': {'timesteps': 1000, 'beta_start': 0.0001, 'beta_end': 0.02}, 'train': {'lr1': 0.0003, 'lr2': 0.0003, 'batch_size1': 16, 'batch_size2': 4096, 'epochs1': 1, 'epochs2': 15, 'max_physical_batch_size': 10, 'num_noise_sample': 4, 'ema_rate': 0.9999, 'ckpt_path': '/rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/vanilla/vanilla_Pretrain_celeba64_celeba64_0725-04:57:57/checkpoints/ema_50.ckpt', 'seed': 42}, 'sample': {'type': 'ddim', 'samplesteps': 200, 'rho': 1.0, 'batch_size': 256, 'guide_scale': 0.0, 'seed': 42}, 'model': {'ch': 128, 'ch_mult': [1, 2, 2, 2], 'num_res_blocks': 2, 'dropout': 0.0, 'attn': [2]}, 'dp': {'max_grad_norm': 0.01, 'delta': 1e-06, 'epsilon': 10.0, 'S': 950, 'sigma': 0.632}}\n",
      "08/09/2025 20:46:35:INFO:Using seed: 42\n",
      "08/09/2025 20:46:35:INFO:Load dataset celeba64\n",
      "08/09/2025 20:46:37:INFO:Satisfy (11.375456173435149, 1e-06)-DP\n",
      "08/09/2025 20:46:38:INFO:Num parameters: 35751939\n",
      "08/09/2025 20:46:38:INFO:Start training...\n",
      "08/09/2025 20:46:38:INFO:Training Phase I...\n",
      "08/09/2025 21:20:31:INFO:Epoch1: loss1 5.986620164130709e-05\n",
      "08/09/2025 21:20:31:INFO:Training Phase II...\n",
      "08/09/2025 23:09:44:INFO:Epoch1: loss1 0.03067710603539222\n",
      "08/10/2025 00:59:28:INFO:Epoch2: loss1 0.020394873859476765\n",
      "08/10/2025 02:48:54:INFO:Epoch3: loss1 0.019918774956894012\n",
      "08/10/2025 04:38:27:INFO:Epoch4: loss1 0.019790080612538227\n",
      "08/10/2025 06:28:09:INFO:Epoch5: loss1 0.01974396251112195\n",
      "08/10/2025 08:17:48:INFO:Epoch6: loss1 0.019512823701723934\n",
      "08/10/2025 10:07:46:INFO:Epoch7: loss1 0.019573546106555772\n",
      "08/10/2025 11:57:19:INFO:Epoch8: loss1 0.019555959543183978\n",
      "08/10/2025 13:46:22:INFO:Epoch9: loss1 0.019451462059267576\n",
      "08/10/2025 15:36:14:INFO:Epoch10: loss1 0.019521404135165264\n",
      "08/10/2025 17:26:13:INFO:Epoch11: loss1 0.019538194928334297\n",
      "08/10/2025 19:16:21:INFO:Epoch12: loss1 0.019516571409584058\n",
      "08/10/2025 21:06:01:INFO:Epoch13: loss1 0.019503180956210057\n",
      "08/10/2025 22:55:27:INFO:Epoch14: loss1 0.01944230669270051\n",
      "08/11/2025 00:45:09:INFO:Epoch15: loss1 0.019547526989663826\n",
      "08/11/2025 00:45:22:INFO:Training complete\n",
      "08/11/2025 00:45:22:INFO:Saving synthesis...\n"
     ]
    }
   ],
   "source": [
    "# Code used for Model training on celeba 64 with Epsilon 10.0\n",
    "!python train.py --config configs/dp_promise/celeba_64/eps10.0/config.yaml --workdir checkpoints/dp-promise --job-id Train_celeba64_Eps10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f4da7-15ef-4f12-a824-59e5e98416dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Evaluation steps for Geenrated Image based on celeba64(Eps - 1, 5 & 10) - calculating IS & FID scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697e33b0-2559-4572-bbba-f5b1517c3325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-30 01:22:21.648047: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-30 01:22:22.546823: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 01:22:23.960410: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-30 01:22:23.960792: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-30 01:22:36.292495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "162079it [28:08, 95.98it/s] \n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                  | 0/1267 [00:00<?, ?it/s]2025-07-30 01:51:37.103044: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|███████████████████████████████████████| 1267/1267 [29:14<00:00,  1.38s/it]\n",
      "Inception Score: (3.2530422, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset statistics for celeba 64\n",
    "!python compute_dataset_stat.py --dataset celeba64 --path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/Data/processed/64_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e080b55f-1093-4e0a-a714-a3de64401806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-04 15:22:30.994531: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-04 15:22:31.745676: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-04 15:22:32.777729: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-04 15:22:32.778052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-04 15:22:50.815177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2025-08-04 15:23:51.730382: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-08-04 15:23:55.938221: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                   | 0/469 [00:00<?, ?it/s]2025-08-04 15:23:58.585581: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|█████████████████████████████████████████| 469/469 [22:27<00:00,  2.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# IS & FID Evaluation - result can be found under evaluation --> result --> celeba64 --> CelebA64_Eps1.0\n",
    "!python eval_vision.py --dataset celeba64 --synthesis_path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/dp-promise/dp-promise_Train_celeba64_Eps1.0_celeba64_eps1.0_0803-05:32:50/evaluation/synthesis.npz --output_path results/celeba64/Eps1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099d3018-ca4e-4fe2-83b9-6df11da81562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 06:18:02.728691: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-11 06:18:03.438464: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-11 06:18:04.382781: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-11 06:18:04.383344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-11 06:18:19.466048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2025-08-11 06:19:17.708052: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-08-11 06:19:21.634321: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                   | 0/469 [00:00<?, ?it/s]2025-08-11 06:19:24.313445: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|█████████████████████████████████████████| 469/469 [22:40<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# IS & FID Evaluation - result can be found under evaluation --> result --> celeba64 --> CelebA64_Eps5.0\n",
    "!python eval_vision.py --dataset celeba64 --synthesis_path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/dp-promise/dp-promise_Train_celeba64_Eps5.0_celeba64_eps5.0_0809-20:46:35/evaluation/synthesis.npz --output_path results/celeba64/Eps5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce361012-7aaf-44b8-8db9-1307cddb9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 05:26:02.028728: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-11 05:26:02.626077: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-11 05:26:03.449669: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-11 05:26:03.449999: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-11 05:26:17.392551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2025-08-11 05:27:13.945522: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-08-11 05:27:18.016715: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/rds/homes/k/kxr414/.local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1094: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  [func(*x) for x in entries],\n",
      "  0%|                                                   | 0/469 [00:00<?, ?it/s]2025-08-11 05:27:20.582598: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "100%|█████████████████████████████████████████| 469/469 [23:37<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# IS & FID Evaluation - result can be found under evaluation --> result --> celeba64 --> CelebA64_Eps10.0\n",
    "!python eval_vision.py --dataset celeba64 --synthesis_path /rds/projects/c/chenhp-dm-mia/Diff-MIA-Attack/DP-Promise_Github/checkpoints/dp-promise/dp-promise_Train_celeba64_Eps10.0_celeba64_eps10.0_0809-20:46:35/evaluation/synthesis.npz --output_path results/celeba64/Eps10.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
